{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 21:46:45.051950: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5\n",
    "\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe94567f1c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.00026958]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# You will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "\n",
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    print(epoch)\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as you go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/Playground/Generate Digits/model.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bsupreme-space-waddle-5px6w9wrwj53x96/workspaces/Playground/Generate%20Digits/model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train(train_dataset, EPOCHS)\n",
      "\u001b[1;32m/workspaces/Playground/Generate Digits/model.ipynb Cell 12\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bsupreme-space-waddle-5px6w9wrwj53x96/workspaces/Playground/Generate%20Digits/model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bsupreme-space-waddle-5px6w9wrwj53x96/workspaces/Playground/Generate%20Digits/model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m image_batch \u001b[39min\u001b[39;00m dataset:\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bsupreme-space-waddle-5px6w9wrwj53x96/workspaces/Playground/Generate%20Digits/model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m   train_step(image_batch)\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bsupreme-space-waddle-5px6w9wrwj53x96/workspaces/Playground/Generate%20Digits/model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Produce images for the GIF as you go\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsupreme-space-waddle-5px6w9wrwj53x96/workspaces/Playground/Generate%20Digits/model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m display\u001b[39m.\u001b[39mclear_output(wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[1;32m    869\u001b[0m   )\n\u001b[1;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1485\u001b[0m   )\n\u001b[1;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
